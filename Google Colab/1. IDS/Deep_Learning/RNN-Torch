{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN-Torch","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPvjCPymVB38E9RJHjD0stt"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"k4t17e8rmNJL","colab_type":"text"},"source":["#**Libs, Hyper Parameter**"]},{"cell_type":"code","metadata":{"id":"SoOriECMl934","colab_type":"code","colab":{}},"source":["import torch \n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper-parameters\n","sequence_length = 28\n","input_size = 28\n","hidden_size = 128\n","num_layers = 2\n","num_classes = 10\n","batch_size = 100\n","num_epochs = 2\n","learning_rate = 0.01"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n74agw4jmTVP","colab_type":"text"},"source":["#**Data**"]},{"cell_type":"code","metadata":{"id":"40kL3pRZmUFQ","colab_type":"code","colab":{}},"source":["# MNIST dataset\n","train_dataset = torchvision.datasets.MNIST(root='../../data/',\n","                                           train=True, \n","                                           transform=transforms.ToTensor(),\n","                                           download=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='../../data/',\n","                                          train=False, \n","                                          transform=transforms.ToTensor())\n","\n","# Data loader\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size, \n","                                          shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"buxvTy00ocHA","colab_type":"text"},"source":["#**Model**"]},{"cell_type":"code","metadata":{"id":"xVoTCoXiocgE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1592671937193,"user_tz":-420,"elapsed":6000,"user":{"displayName":"Tien LE KHAC","photoUrl":"","userId":"18298916241916904857"}},"outputId":"112674de-0177-40ff-a13c-741a67fc5969"},"source":["# Recurrent neural network (many-to-one)\n","class RNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(RNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","    \n","    def forward(self, x):\n","        # Set initial hidden and cell states \n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","        \n","        # Forward propagate LSTM\n","        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n","        \n","        # Decode the hidden state of the last time step\n","        out = self.fc(out[:, -1, :])\n","        return out\n","\n","model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"240Kgb76ogiL","colab_type":"text"},"source":["#**Run**"]},{"cell_type":"code","metadata":{"id":"We5PYo0IohO5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1592672064368,"user_tz":-420,"elapsed":133168,"user":{"displayName":"Tien LE KHAC","photoUrl":"","userId":"18298916241916904857"}},"outputId":"0b996fe6-27f2-4412-985a-3606d62fe018"},"source":["# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Train the model\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.reshape(-1, sequence_length, input_size).to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","\n","# Test the model\n","model.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.reshape(-1, sequence_length, input_size).to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) \n","\n","# Save the model checkpoint\n","torch.save(model.state_dict(), 'RNN.ckpt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch [1/2], Step [100/600], Loss: 0.4145\n","Epoch [1/2], Step [200/600], Loss: 0.1193\n","Epoch [1/2], Step [300/600], Loss: 0.1257\n","Epoch [1/2], Step [400/600], Loss: 0.1278\n","Epoch [1/2], Step [500/600], Loss: 0.1936\n","Epoch [1/2], Step [600/600], Loss: 0.0821\n","Epoch [2/2], Step [100/600], Loss: 0.0765\n","Epoch [2/2], Step [200/600], Loss: 0.0647\n","Epoch [2/2], Step [300/600], Loss: 0.0472\n","Epoch [2/2], Step [400/600], Loss: 0.0568\n","Epoch [2/2], Step [500/600], Loss: 0.0466\n","Epoch [2/2], Step [600/600], Loss: 0.0492\n","Test Accuracy of the model on the 10000 test images: 97.34 %\n"],"name":"stdout"}]}]}